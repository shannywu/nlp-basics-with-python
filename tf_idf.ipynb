{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fu = utils.FileUtil()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'Natural language processing (NLP) is a subfield of computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages.',\n",
    "    'Challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural language generation.',\n",
    "    'The history of natural language processing generally started in the 1950s, although work can be found from earlier periods.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing(doc):\n",
    "    \"\"\"\n",
    "    return tokens\n",
    "    \"\"\"\n",
    "    words = fu.get_words(doc, lower_case=True, remove_stop_words=True)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_tf(word, word_count):    \n",
    "    return word_count[word]/sum(word_count.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_idf(word, all_docs):\n",
    "    df = 0\n",
    "    for doc in all_docs:\n",
    "        if word in doc:\n",
    "            df += 1\n",
    "    idf = math.log(len(all_docs) / df) + 1\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = defaultdict(lambda: defaultdict(float))\n",
    "processed_corpus = [pre_processing(doc) for doc in corpus]\n",
    "all_words = set([word for doc in processed_corpus for word in doc])\n",
    "\n",
    "for i, doc in enumerate(processed_corpus):\n",
    "    for word in all_words:\n",
    "        tf_idf_value = compute_tf(word, Counter(doc)) * compute_idf(word, processed_corpus)\n",
    "        tf_idf[word][i] = tf_idf_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>work</th>\n",
       "      <th>history</th>\n",
       "      <th>information</th>\n",
       "      <th>concerned</th>\n",
       "      <th>computer</th>\n",
       "      <th>subfield</th>\n",
       "      <th>science</th>\n",
       "      <th>found</th>\n",
       "      <th>speech</th>\n",
       "      <th>...</th>\n",
       "      <th>computers</th>\n",
       "      <th>recognition</th>\n",
       "      <th>engineering</th>\n",
       "      <th>artificial</th>\n",
       "      <th>processing</th>\n",
       "      <th>challenges</th>\n",
       "      <th>human</th>\n",
       "      <th>frequently</th>\n",
       "      <th>intelligence</th>\n",
       "      <th>generally</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123448</td>\n",
       "      <td>0.123448</td>\n",
       "      <td>0.123448</td>\n",
       "      <td>0.123448</td>\n",
       "      <td>0.123448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123448</td>\n",
       "      <td>0.123448</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123448</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.149901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.149901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.174884</td>\n",
       "      <td>0.174884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.174884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   language      work   history  information  concerned  computer  subfield  \\\n",
       "0  0.058824  0.000000  0.000000     0.123448   0.123448  0.123448  0.123448   \n",
       "1  0.214286  0.000000  0.000000     0.000000   0.000000  0.000000  0.000000   \n",
       "2  0.083333  0.174884  0.174884     0.000000   0.000000  0.000000  0.000000   \n",
       "\n",
       "    science     found    speech    ...      computers  recognition  \\\n",
       "0  0.123448  0.000000  0.000000    ...       0.123448     0.000000   \n",
       "1  0.000000  0.000000  0.149901    ...       0.000000     0.149901   \n",
       "2  0.000000  0.174884  0.000000    ...       0.000000     0.000000   \n",
       "\n",
       "   engineering  artificial  processing  challenges     human  frequently  \\\n",
       "0     0.123448    0.123448    0.058824    0.000000  0.123448    0.000000   \n",
       "1     0.000000    0.000000    0.071429    0.149901  0.000000    0.149901   \n",
       "2     0.000000    0.000000    0.083333    0.000000  0.000000    0.000000   \n",
       "\n",
       "   intelligence  generally  \n",
       "0      0.123448   0.000000  \n",
       "1      0.000000   0.000000  \n",
       "2      0.000000   0.174884  \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame.from_dict(tf_idf)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use TfidfVectorizer from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1950s', 'although', 'and', 'artificial', 'be', 'between', 'can', 'challenges', 'computer', 'computers', 'concerned', 'earlier', 'engineering', 'found', 'frequently', 'from', 'generally', 'generation', 'history', 'human', 'in', 'information', 'intelligence', 'interactions', 'involve', 'is', 'language', 'languages', 'natural', 'nlp', 'of', 'periods', 'processing', 'recognition', 'science', 'speech', 'started', 'subfield', 'the', 'understanding', 'with', 'work']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(smooth_idf=False)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 42)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.29910492, 0.22330873, 0.        ,\n",
       "        0.22330873, 0.        , 0.        , 0.22330873, 0.22330873,\n",
       "        0.22330873, 0.        , 0.22330873, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.22330873,\n",
       "        0.        , 0.22330873, 0.22330873, 0.22330873, 0.        ,\n",
       "        0.22330873, 0.10640781, 0.22330873, 0.21281562, 0.22330873,\n",
       "        0.14955246, 0.        , 0.10640781, 0.        , 0.22330873,\n",
       "        0.        , 0.        , 0.22330873, 0.14955246, 0.        ,\n",
       "        0.22330873, 0.        ],\n",
       "       [0.        , 0.        , 0.19165059, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.28616881, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.28616881,\n",
       "        0.        , 0.        , 0.28616881, 0.        , 0.        ,\n",
       "        0.19165059, 0.        , 0.        , 0.        , 0.28616881,\n",
       "        0.        , 0.40908292, 0.        , 0.40908292, 0.        ,\n",
       "        0.        , 0.        , 0.13636097, 0.28616881, 0.        ,\n",
       "        0.28616881, 0.        , 0.        , 0.        , 0.28616881,\n",
       "        0.        , 0.        ],\n",
       "       [0.25505346, 0.25505346, 0.        , 0.        , 0.25505346,\n",
       "        0.        , 0.25505346, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.25505346, 0.        , 0.25505346, 0.        ,\n",
       "        0.25505346, 0.25505346, 0.        , 0.25505346, 0.        ,\n",
       "        0.17081228, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.12153434, 0.        , 0.12153434, 0.        ,\n",
       "        0.17081228, 0.25505346, 0.12153434, 0.        , 0.        ,\n",
       "        0.        , 0.25505346, 0.        , 0.34162455, 0.        ,\n",
       "        0.        , 0.25505346]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit_transform(corpus).toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
